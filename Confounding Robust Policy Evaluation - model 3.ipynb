{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confounding Robust Policy Evaluation - model 3\n",
    "We evaluate the worst case regret of a policy $\\pi$ relative to a baseline policy $\\pi_0$ as presented in [Kallus et al.](https://arxiv.org/pdf/1805.08593.pdf)  \n",
    "\n",
    "\n",
    "The model we are using:  \n",
    "Medical Treatment model as defined in Appendix A in https://causalai.net/mdp-causal.pdf  \n",
    "Here, there is a slight difference in physician's policy to make it more asymmetrical. Here,  \n",
    "$P(E_t = 1) = 0.3$ and $P(M_t = 1) = 0.75$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def physicains_policy(St, Mt, Et):\n",
    "    return (St+Mt+Et) % 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability_yt_is_1 is a 4 dimensional array\n",
    "# format: probability_yt_is_1[St][Mt][Et][Xt] is P(Yt = 1 | Xt, St, Mt, Et)\n",
    "probability_yt_is_1 = np.zeros((2,2,2,2))\n",
    "probability_yt_is_1[0][0][0][0] = 0.2\n",
    "probability_yt_is_1[0][0][0][1] = 0.9\n",
    "probability_yt_is_1[0][0][1][0] = 0.9\n",
    "probability_yt_is_1[0][0][1][1] = 0.2\n",
    "probability_yt_is_1[0][1][0][0] = 0.8\n",
    "probability_yt_is_1[0][1][0][1] = 0.3\n",
    "probability_yt_is_1[0][1][1][0] = 0.3\n",
    "probability_yt_is_1[0][1][1][1] = 0.8\n",
    "\n",
    "probability_yt_is_1[1][0][0][0] = 0.7\n",
    "probability_yt_is_1[1][0][0][1] = 0.2\n",
    "probability_yt_is_1[1][0][1][0] = 0.2\n",
    "probability_yt_is_1[1][0][1][1] = 0.7\n",
    "probability_yt_is_1[1][1][0][0] = 0.1\n",
    "probability_yt_is_1[1][1][0][1] = 0.8\n",
    "probability_yt_is_1[1][1][1][0] = 0.8\n",
    "probability_yt_is_1[1][1][1][1] = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transition_prob is a 2 dimensional array\n",
    "# format: transition_prob[Xt][St] = P(St+1 = 0 | St, Xt)\n",
    "transition_prob = np.zeros((2,2))\n",
    "transition_prob[0][0] = 0.9\n",
    "transition_prob[0][1] = 0.3\n",
    "transition_prob[1][0] = 0.7\n",
    "transition_prob[1][1] = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Yt(St, Mt, Et, Xt):\n",
    "    u = np.random.rand()\n",
    "    if u < probability_yt_is_1[St][Mt][Et][Xt]:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_state(St, Xt):\n",
    "    u = np.random.rand()\n",
    "    if u < transition_prob[Xt][St]:\n",
    "        return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_st_and_mt():\n",
    "    u1, u2 = np.random.rand(), np.random.rand()\n",
    "    if u1 < 0.3:\n",
    "        Et = 1\n",
    "    else:\n",
    "        Et = 0\n",
    "    if u2 < 0.75:\n",
    "        Mt = 1\n",
    "    else:\n",
    "        Mt = 0\n",
    "    return Et, Mt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_single_trajectory(patient_id):\n",
    "    global data_df\n",
    "    St = np.random.randint(2)\n",
    "    for t in range(100):\n",
    "        Et, Mt = get_st_and_mt()\n",
    "        Xt = physicains_policy(St, Mt, Et)\n",
    "        Yt = get_Yt(St, Mt, Et, Xt)\n",
    "        data_df = data_df.append({'pt_id': patient_id,'t': t, 'St': St, 'Mt': Mt, 'Et': Et, 'Xt': Xt, 'Yt': Yt}, ignore_index=True)\n",
    "        St = get_next_state(St, Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for patient_id in range(1000):\n",
    "    if patient_id % 100 == 0:\n",
    "        print(\"Iteration number: \", patient_id)\n",
    "    generate_single_trajectory(patient_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_csv('/Users/faaiz/MDPUC/data-model3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = data_df['pt_id'].unique()\n",
    "training = patients[np.random.randint(5, size = (len(patients))) != 4]\n",
    "testing = patients[np.random.randint(5, size = (len(patients))) == 4]\n",
    "\n",
    "train_data = data_df.loc[data_df['pt_id'].isin(training)].reset_index()\n",
    "test_data = data_df.loc[data_df['pt_id'].isin(testing)].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the physician's policy. \n",
    "We will use this as the baseline $\\pi_0$ when calculating the worst case regret for our policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util_functions import *\n",
    "\n",
    "sums = compute_state_action_visits(train_data, n_states=2, n_actions=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "physpol = (sums.T/((sums.sum(axis=1)==0) + (sums.sum(axis=1)))).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our policy $\\pi$ is obtained by 'softening' the deterministic policy  \n",
    "$\\pi(X_t = 0 | S_t = 0) = 1$  \n",
    "$\\pi(X_t = 1 | S_t = 1) = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95, 0.05],\n",
       "       [0.05, 0.95]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi = np.zeros((2,2))\n",
    "pi[0][0] = 0.95\n",
    "pi[0][1] = 0.05\n",
    "pi[1][0] = 0.05\n",
    "pi[1][1] = 0.95\n",
    "pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating nominal propensities $P[X_t = x | S_t = s]$ from data\n",
    "We can just estimate this from the physician's policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "propensity = physpol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of this analysis, we assume $\\Gamma = 1.2$. We will calibrate the value of $\\Gamma$ when doing a more careful analysis.  \n",
    "Here $\\Gamma$ is defined as a bound $\\Gamma\\geq1$, such that:  \n",
    "$\\Gamma^{-1}\\leq\\frac{(1-\\tilde{e}_T(X))e_T(X,Y)}{\\tilde{e}_T(X)(1-e_T(X,Y))}\\leq\\Gamma$  \n",
    "here $\\tilde{e}_T(X) = P(T=t | X=x)$  \n",
    "and $e_T(X,Y)=P(T=t | X=x, Y(t) = y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use **Theorem 11** in [Kallus et al.](https://arxiv.org/pdf/1805.08593.pdf) to calculate the worst case regret. In order to do this, we must first compute $r_i$, $a_i^\\Gamma$ and $b_i^\\Gamma$ values as defined in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 1.2\n",
    "cr_data = train_data.copy()\n",
    "for index, row in cr_data.iterrows():\n",
    "    cr_data.at[index, 'r'] = (physpol[int(row['St'])][int(row['Xt'])]-pi[int(row['St'])][int(row['Xt'])])*row['Yt']\n",
    "    cr_data.at[index, 'a'] = 1 + 1/gamma*(1/propensity[int(row['St'])][int(row['Xt'])] - 1)\n",
    "    cr_data.at[index, 'b'] = 1 + gamma*(1/propensity[int(row['St'])][int(row['Xt'])] - 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Et</th>\n",
       "      <th>Mt</th>\n",
       "      <th>St</th>\n",
       "      <th>Xt</th>\n",
       "      <th>Yt</th>\n",
       "      <th>pt_id</th>\n",
       "      <th>t</th>\n",
       "      <th>r</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.551680</td>\n",
       "      <td>1.794420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.551679</td>\n",
       "      <td>2.258781</td>\n",
       "      <td>2.812644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>2.258781</td>\n",
       "      <td>2.812644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>2.258781</td>\n",
       "      <td>2.812644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.551679</td>\n",
       "      <td>1.551680</td>\n",
       "      <td>1.794420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   Et   Mt   St   Xt   Yt  pt_id    t         r         a         b\n",
       "0      0  0.0  1.0  0.0  1.0  0.0    0.0  0.0  0.000000  1.551680  1.794420\n",
       "1      1  0.0  0.0  0.0  0.0  1.0    0.0  1.0 -0.551679  2.258781  2.812644\n",
       "2      2  0.0  0.0  0.0  0.0  0.0    0.0  2.0 -0.000000  2.258781  2.812644\n",
       "3      3  0.0  0.0  0.0  0.0  0.0    0.0  3.0 -0.000000  2.258781  2.812644\n",
       "4      4  0.0  1.0  0.0  1.0  1.0    0.0  4.0  0.551679  1.551680  1.794420"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_data_sorted = cr_data.sort_values(by='r').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>Et</th>\n",
       "      <th>Mt</th>\n",
       "      <th>St</th>\n",
       "      <th>Xt</th>\n",
       "      <th>Yt</th>\n",
       "      <th>pt_id</th>\n",
       "      <th>t</th>\n",
       "      <th>r</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16864</td>\n",
       "      <td>21264</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>-0.551679</td>\n",
       "      <td>2.258781</td>\n",
       "      <td>2.812644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6909</td>\n",
       "      <td>9209</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.551679</td>\n",
       "      <td>2.258781</td>\n",
       "      <td>2.812644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10884</td>\n",
       "      <td>13884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>-0.551679</td>\n",
       "      <td>2.258781</td>\n",
       "      <td>2.812644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24986</td>\n",
       "      <td>31186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>-0.551679</td>\n",
       "      <td>2.258781</td>\n",
       "      <td>2.812644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13817</td>\n",
       "      <td>17217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-0.551679</td>\n",
       "      <td>2.258781</td>\n",
       "      <td>2.812644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  index   Et   Mt   St   Xt   Yt  pt_id     t         r         a  \\\n",
       "0    16864  21264  1.0  1.0  0.0  0.0  1.0  212.0  64.0 -0.551679  2.258781   \n",
       "1     6909   9209  1.0  1.0  0.0  0.0  1.0   92.0   9.0 -0.551679  2.258781   \n",
       "2    10884  13884  0.0  0.0  0.0  0.0  1.0  138.0  84.0 -0.551679  2.258781   \n",
       "3    24986  31186  0.0  0.0  0.0  0.0  1.0  311.0  86.0 -0.551679  2.258781   \n",
       "4    13817  17217  1.0  1.0  0.0  0.0  1.0  172.0  17.0 -0.551679  2.258781   \n",
       "\n",
       "          b  \n",
       "0  2.812644  \n",
       "1  2.812644  \n",
       "2  2.812644  \n",
       "3  2.812644  \n",
       "4  2.812644  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr_data_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lambda(k, data_sorted):\n",
    "    num = ((data_sorted.index<k)*(data_sorted['a']*data_sorted['r'])).sum() +\\\n",
    "    ((data_sorted.index>=k)*(data_sorted['b']*data_sorted['r'])).sum()\n",
    "    den = ((data_sorted.index<k)*data_sorted['a']).sum() +\\\n",
    "    ((data_sorted.index>=k)*data_sorted['b']).sum()\n",
    "    return num/den    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As proved in the paper, the worst case regret estimate $\\hat{\\bar{Q}}(r;W_n^\\Gamma) = \\lambda(k^*)$  \n",
    "where $k^* = \\inf\\{k=1,\\dots,n+1:\\lambda(k)<\\lambda(k-1)\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst case regret is 0.014751351154487691\n"
     ]
    }
   ],
   "source": [
    "lbd = compute_lambda(0, cr_data_sorted)\n",
    "next_lbd = compute_lambda(1, cr_data_sorted)\n",
    "i = 2\n",
    "while i < len(cr_data_sorted) and  lbd <= next_lbd:\n",
    "    lbd = next_lbd\n",
    "    next_lbd = compute_lambda(i, cr_data_sorted)\n",
    "    i += 1\n",
    "if next_lbd < lbd:\n",
    "    print('Worst case regret is', next_lbd)\n",
    "else:\n",
    "    print('k* is infinity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bring this all together in a function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_worst_case_regret(data, pi, pi0, gamma):\n",
    "    n_states = len(pi)\n",
    "    n_actions = len(pi[0])\n",
    "    sums = compute_state_action_visits(data, n_states, n_actions)\n",
    "    physpol = (sums.T/((sums.sum(axis=1)==0) + (sums.sum(axis=1)))).T\n",
    "    propensity = physpol\n",
    "    cr_data = data.copy()\n",
    "    for index, row in cr_data.iterrows():\n",
    "        cr_data.at[index, 'r'] = (physpol[int(row['St'])][int(row['Xt'])]-pi[int(row['St'])][int(row['Xt'])])*row['Yt']\n",
    "        cr_data.at[index, 'a'] = 1 + 1/gamma*(1/propensity[int(row['St'])][int(row['Xt'])] - 1)\n",
    "        cr_data.at[index, 'b'] = 1 + gamma*(1/propensity[int(row['St'])][int(row['Xt'])] - 1)\n",
    "    cr_data_sorted = cr_data.sort_values(by='r').reset_index()\n",
    "    lbd = compute_lambda(0, cr_data_sorted)\n",
    "    next_lbd = compute_lambda(1, cr_data_sorted)\n",
    "    i = 2\n",
    "    while i < len(cr_data_sorted) and  lbd <= next_lbd:\n",
    "        lbd = next_lbd\n",
    "        next_lbd = compute_lambda(i, cr_data_sorted)\n",
    "        i += 1\n",
    "    if next_lbd < lbd:\n",
    "        print('Worst case regret is', next_lbd)\n",
    "        return next_lbd\n",
    "    else:\n",
    "        print('k* is infinity')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the same with policy $\\pi$ obtained by 'softening' the deterministic policy  \n",
    "$\\pi(X_t = 1 | S_t = 0) = 1$  \n",
    "$\\pi(X_t = 0 | S_t = 1) = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05, 0.95],\n",
       "       [0.95, 0.05]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi = np.zeros((2,2))\n",
    "pi[0][0] = 0.05\n",
    "pi[0][1] = 0.95\n",
    "pi[1][0] = 0.95\n",
    "pi[1][1] = 0.05\n",
    "pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst case regret is 0.005962859346932289\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.005962859346932289"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_worst_case_regret(train_data, pi, physpol, gamma=1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the degree of unmeasured confounding\n",
    "Now let's assume that we only have access to $S_t$ and $E_t$. $M_t$ is an unobserved confounder. In this case, the state space has 4 states. The action space remains unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Et</th>\n",
       "      <th>Mt</th>\n",
       "      <th>St</th>\n",
       "      <th>Xt</th>\n",
       "      <th>Yt</th>\n",
       "      <th>pt_id</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   Et   Mt   St   Xt   Yt  pt_id    t\n",
       "0      0  0.0  1.0  0.0  1.0  0.0    0.0  0.0\n",
       "1      1  0.0  0.0  0.0  0.0  1.0    0.0  1.0\n",
       "2      2  0.0  0.0  0.0  0.0  0.0    0.0  2.0\n",
       "3      3  0.0  0.0  0.0  0.0  0.0    0.0  3.0\n",
       "4      4  0.0  1.0  0.0  1.0  1.0    0.0  4.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_model2 = train_data.copy()\n",
    "train_data_model2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>St</th>\n",
       "      <th>Xt</th>\n",
       "      <th>Yt</th>\n",
       "      <th>pt_id</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   St   Xt   Yt  pt_id    t\n",
       "0      0  0.0  1.0  0.0    0.0  0.0\n",
       "1      1  0.0  0.0  1.0    0.0  1.0\n",
       "2      2  0.0  0.0  0.0    0.0  2.0\n",
       "3      3  0.0  0.0  0.0    0.0  3.0\n",
       "4      4  0.0  1.0  1.0    0.0  4.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_model2['St'] = train_data_model2['St'] + 2*train_data_model2['Et']\n",
    "train_data_model2.drop(columns = ['Et', 'Mt'], inplace=True)\n",
    "train_data_model2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal policy $\\pi^*$\n",
    "We know from the complete model dynamics that the optimal policy $\\pi^*$ in this case is:  \n",
    "$(S_t, E_t)$ -> Optimal Action  \n",
    "(0,0) -> 1  \n",
    "(0,1) -> 0  \n",
    "(1,0) -> 1  \n",
    "(1,1) -> 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soften_deterministic_policy(policy):\n",
    "    p = 0.05\n",
    "    n_states = len(policy)\n",
    "    n_actions = len(policy[0])\n",
    "    for i in range(len(policy)):\n",
    "        for j in range(len(policy[i])):\n",
    "            if policy[i][j] == 0:\n",
    "                policy[i][j] = p/(n_actions-1)\n",
    "            elif policy[i][j] == 1:\n",
    "                policy[i][j] = 1-p\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A policy which always picks action 0 must have higher regret than the optimal policy $\\pi^*$ relative to the physician's policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95, 0.05],\n",
       "       [0.95, 0.05],\n",
       "       [0.95, 0.05],\n",
       "       [0.95, 0.05]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi = np.zeros((4,2))\n",
    "pi[0][0] = 1\n",
    "pi[1][0] = 1\n",
    "pi[2][0] = 1\n",
    "pi[3][0] = 1\n",
    "soften_deterministic_policy(pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2468884 , 0.7531116 ],\n",
       "       [0.75356619, 0.24643381],\n",
       "       [0.74812757, 0.25187243],\n",
       "       [0.25157401, 0.74842599]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sums = compute_state_action_visits(train_data_model2, n_states=4, n_actions=2)\n",
    "physpol = (sums.T/((sums.sum(axis=1)==0) + (sums.sum(axis=1)))).T\n",
    "physpol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst case regret is 0.025080322071306414\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.025080322071306414"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_worst_case_regret(train_data_model2, soften_deterministic_policy(pi), physpol, gamma=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_star = np.zeros((4,2))\n",
    "pi_star[0][1] = 1\n",
    "pi_star[1][1] = 1\n",
    "pi_star[2][0] = 1\n",
    "pi_star[3][0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst case regret is -0.011051029909470916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.011051029909470916"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_worst_case_regret(train_data_model2, soften_deterministic_policy(pi_star), physpol, gamma=1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat this with policy $\\pi$ which is complement to the optimal policy $\\pi^*$.  \n",
    "This is, of course, the worst policy in terms of value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = np.zeros((4,2))\n",
    "pi[0][0] = 1\n",
    "pi[1][0] = 1\n",
    "pi[2][1] = 1\n",
    "pi[3][1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst case regret is 0.04131427647793238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.04131427647793238"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_worst_case_regret(train_data_model2, soften_deterministic_policy(pi), physpol, gamma=1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute worst case regret for a uniform policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5, 0.5],\n",
       "       [0.5, 0.5],\n",
       "       [0.5, 0.5],\n",
       "       [0.5, 0.5]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi = np.ones((4,2))*0.5\n",
    "pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst case regret is 0.01033874507388746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.01033874507388746"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_worst_case_regret(train_data_model2, pi, physpol, gamma=1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy evaluations and worst case regret under unobserved confounding\n",
    "We do a systematic analysis of all deterministic policies, comparing their value (using Weighted Importance Sampling, assuming no unobserved confounding) to their worst case regret, relative to the physician's policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_deterministic_policies(n_states, n_actions):\n",
    "    result = []\n",
    "    for i in range(n_actions**n_states):\n",
    "        policy = np.zeros(n_states)\n",
    "        policy[0] = i%2 \n",
    "        policy[1] = ((i-policy[0])/2) % 2 \n",
    "        policy[2] = ((i-policy[0]-2*policy[1])/4) % 2\n",
    "        policy[3] = ((i-policy[0]-2*policy[1] - 4*policy[2])/8) % 2\n",
    "        result.append(policy)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_policy_into_softened_matrix(policy, n_actions):\n",
    "    pi = np.zeros((len(policy), n_actions))\n",
    "    for s in range(len(policy)):\n",
    "        pi[s][int(policy[s])] = 1\n",
    "    return soften_deterministic_policy(pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bootwis_estimator</th>\n",
       "      <th>policy</th>\n",
       "      <th>worst_case_regret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.849613</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0.025080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.611379</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>-0.003182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.553125</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>0.016080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.983051</td>\n",
       "      <td>[1.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>-0.011051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.102709</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>0.037798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16.761323</td>\n",
       "      <td>[1.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>0.008874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11.933816</td>\n",
       "      <td>[0.0, 1.0, 1.0, 0.0]</td>\n",
       "      <td>0.028842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.614686</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.0]</td>\n",
       "      <td>-0.000154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.101396</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>0.028615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12.649414</td>\n",
       "      <td>[1.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>-0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12.378043</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0]</td>\n",
       "      <td>0.019654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15.398756</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0]</td>\n",
       "      <td>-0.007925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14.984175</td>\n",
       "      <td>[0.0, 0.0, 1.0, 1.0]</td>\n",
       "      <td>0.041314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16.136879</td>\n",
       "      <td>[1.0, 0.0, 1.0, 1.0]</td>\n",
       "      <td>0.012431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12.025527</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>0.032397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12.659561</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>0.003417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bootwis_estimator                policy  worst_case_regret\n",
       "0           16.849613  [0.0, 0.0, 0.0, 0.0]           0.025080\n",
       "1           14.611379  [1.0, 0.0, 0.0, 0.0]          -0.003182\n",
       "2           12.553125  [0.0, 1.0, 0.0, 0.0]           0.016080\n",
       "3           15.983051  [1.0, 1.0, 0.0, 0.0]          -0.011051\n",
       "4           16.102709  [0.0, 0.0, 1.0, 0.0]           0.037798\n",
       "5           16.761323  [1.0, 0.0, 1.0, 0.0]           0.008874\n",
       "6           11.933816  [0.0, 1.0, 1.0, 0.0]           0.028842\n",
       "7           12.614686  [1.0, 1.0, 1.0, 0.0]          -0.000154\n",
       "8           14.101396  [0.0, 0.0, 0.0, 1.0]           0.028615\n",
       "9           12.649414  [1.0, 0.0, 0.0, 1.0]          -0.000086\n",
       "10          12.378043  [0.0, 1.0, 0.0, 1.0]           0.019654\n",
       "11          15.398756  [1.0, 1.0, 0.0, 1.0]          -0.007925\n",
       "12          14.984175  [0.0, 0.0, 1.0, 1.0]           0.041314\n",
       "13          16.136879  [1.0, 0.0, 1.0, 1.0]           0.012431\n",
       "14          12.025527  [0.0, 1.0, 1.0, 1.0]           0.032397\n",
       "15          12.659561  [1.0, 1.0, 1.0, 1.0]           0.003417"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from offpolicy_eval import *\n",
    "\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "n_states = 4\n",
    "n_actions = 2\n",
    "\n",
    "policies = get_all_deterministic_policies(n_states, n_actions)\n",
    "\n",
    "for pi in policies:\n",
    "    _, bootwis_estimator = evaluate_policy(train_data_model2, pi, n_states, n_actions, 0.99, n_iters=50)\n",
    "    pi_mat = turn_policy_into_softened_matrix(pi, n_actions)\n",
    "    regret = compute_worst_case_regret(train_data_model2, pi_mat, physpol, gamma=1.2)\n",
    "    results_df = results_df.append({'policy': pi, 'bootwis_estimator': bootwis_estimator.mean(), 'worst_case_regret': regret}, ignore_index=True)\n",
    "    \n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = results_df['bootwis_estimator']\n",
    "y = results_df['worst_case_regret']\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel('WIS estimator value')\n",
    "plt.ylabel('Worst case regret')\n",
    "plt.title('Regret vs WIS estimator')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above shows that worst case regret is a better proxy for policy value than WIS estimator. For instance,  \n",
    "The optimal policy $\\pi^*$ has lowest regret, but not the highest WIS estimator value.  \n",
    "Similarly the worst policy $\\pi$, which acts suboptimally at each decision, has the highest regret, whereas it's WIS estimator value is still quite high."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
