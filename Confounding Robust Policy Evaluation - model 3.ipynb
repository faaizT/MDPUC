{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confounding Robust Policy Evaluation - model 3\n",
    "We evaluate the worst case regret of a policy $\\pi$ relative to a baseline policy $\\pi_0$ as presented in [Kallus et al.](https://arxiv.org/pdf/1805.08593.pdf)  \n",
    "\n",
    "\n",
    "The model we are using:  \n",
    "Medical Treatment model as defined in Appendix A in https://causalai.net/mdp-causal.pdf  \n",
    "Here, there is a slight difference in physician's policy to make it more asymmetrical. Here,  \n",
    "$P(E_t = 1) = 0.3$ and $P(M_t = 1) = 0.75$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def physicains_policy(St, Mt, Et):\n",
    "    return (St+Mt+Et) % 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability_yt_is_1 is a 4 dimensional array\n",
    "# format: probability_yt_is_1[St][Mt][Et][Xt] is P(Yt = 1 | Xt, St, Mt, Et)\n",
    "probability_yt_is_1 = np.zeros((2,2,2,2))\n",
    "probability_yt_is_1[0][0][0][0] = 0.2\n",
    "probability_yt_is_1[0][0][0][1] = 0.9\n",
    "probability_yt_is_1[0][0][1][0] = 0.9\n",
    "probability_yt_is_1[0][0][1][1] = 0.2\n",
    "probability_yt_is_1[0][1][0][0] = 0.8\n",
    "probability_yt_is_1[0][1][0][1] = 0.3\n",
    "probability_yt_is_1[0][1][1][0] = 0.3\n",
    "probability_yt_is_1[0][1][1][1] = 0.8\n",
    "\n",
    "probability_yt_is_1[1][0][0][0] = 0.7\n",
    "probability_yt_is_1[1][0][0][1] = 0.2\n",
    "probability_yt_is_1[1][0][1][0] = 0.2\n",
    "probability_yt_is_1[1][0][1][1] = 0.7\n",
    "probability_yt_is_1[1][1][0][0] = 0.1\n",
    "probability_yt_is_1[1][1][0][1] = 0.8\n",
    "probability_yt_is_1[1][1][1][0] = 0.8\n",
    "probability_yt_is_1[1][1][1][1] = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transition_prob is a 2 dimensional array\n",
    "# format: transition_prob[Xt][St] = P(St+1 = 0 | St, Xt)\n",
    "transition_prob = np.zeros((2,2))\n",
    "transition_prob[0][0] = 0.9\n",
    "transition_prob[0][1] = 0.3\n",
    "transition_prob[1][0] = 0.7\n",
    "transition_prob[1][1] = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Yt(St, Mt, Et, Xt):\n",
    "    u = np.random.rand()\n",
    "    if u < probability_yt_is_1[St][Mt][Et][Xt]:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_state(St, Xt):\n",
    "    u = np.random.rand()\n",
    "    if u < transition_prob[Xt][St]:\n",
    "        return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_st_and_mt():\n",
    "    u1, u2 = np.random.rand(), np.random.rand()\n",
    "    if u1 < 0.3:\n",
    "        Et = 1\n",
    "    else:\n",
    "        Et = 0\n",
    "    if u2 < 0.75:\n",
    "        Mt = 1\n",
    "    else:\n",
    "        Mt = 0\n",
    "    return Et, Mt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_single_trajectory(patient_id):\n",
    "    global data_df\n",
    "    St = np.random.randint(2)\n",
    "    for t in range(100):\n",
    "        Et, Mt = get_st_and_mt()\n",
    "        Xt = physicains_policy(St, Mt, Et)\n",
    "        Yt = get_Yt(St, Mt, Et, Xt)\n",
    "        data_df = data_df.append({'pt_id': patient_id,'t': t, 'St': St, 'Mt': Mt, 'Et': Et, 'Xt': Xt, 'Yt': Yt}, ignore_index=True)\n",
    "        St = get_next_state(St, Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for patient_id in range(1000):\n",
    "    if patient_id % 100 == 0:\n",
    "        print(\"Iteration number: \", patient_id)\n",
    "    generate_single_trajectory(patient_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_csv('/Users/faaiz/MDPUC/data-model3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = data_df['pt_id'].unique()\n",
    "training = patients[np.random.randint(5, size = (len(patients))) != 4]\n",
    "testing = patients[np.random.randint(5, size = (len(patients))) == 4]\n",
    "\n",
    "train_data = data_df.loc[data_df['pt_id'].isin(training)].reset_index()\n",
    "test_data = data_df.loc[data_df['pt_id'].isin(testing)].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the physician's policy. \n",
    "We will use this as the baseline $\\pi_0$ when calculating the worst case regret for our policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util_functions import *\n",
    "\n",
    "sums = compute_state_action_visits(train_data, n_states=2, n_actions=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "physpol = (sums.T/((sums.sum(axis=1)==0) + (sums.sum(axis=1)))).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our policy $\\pi$ is obtained by 'softening' the deterministic policy  \n",
    "$\\pi(X_t = 0 | S_t = 0) = 1$  \n",
    "$\\pi(X_t = 1 | S_t = 1) = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95, 0.05],\n",
       "       [0.05, 0.95]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi = np.zeros((2,2))\n",
    "pi[0][0] = 0.95\n",
    "pi[0][1] = 0.05\n",
    "pi[1][0] = 0.05\n",
    "pi[1][1] = 0.95\n",
    "pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating nominal propensities $P[X_t = x | S_t = s]$ from data\n",
    "We can just estimate this from the physician's policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "propensity = physpol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of this analysis, we assume $\\Gamma = 1.2$. We will calibrate the value of $\\Gamma$ when doing a more careful analysis.  \n",
    "Here $\\Gamma$ is defined as a bound $\\Gamma\\geq1$, such that:  \n",
    "$\\Gamma^{-1}\\leq\\frac{(1-\\tilde{e}_T(X))e_T(X,Y)}{\\tilde{e}_T(X)(1-e_T(X,Y))}\\leq\\Gamma$  \n",
    "here $\\tilde{e}_T(X) = P(T=t | X=x)$  \n",
    "and $e_T(X,Y)=P(T=t | X=x, Y(t) = y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use **Theorem 11** in [Kallus et al.](https://arxiv.org/pdf/1805.08593.pdf) to calculate the worst case regret. In order to do this, we must first compute $r_i$, $a_i^\\Gamma$ and $b_i^\\Gamma$ values as defined in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 1.2\n",
    "cr_data = train_data.copy()\n",
    "for index, row in cr_data.iterrows():\n",
    "    cr_data.at[index, 'r'] = (physpol[int(row['St'])][int(row['Xt'])]-pi[int(row['St'])][int(row['Xt'])])*row['Yt']\n",
    "    cr_data.at[index, 'a'] = 1 + 1/gamma*(1/propensity[int(row['St'])][int(row['Xt'])] - 1)\n",
    "    cr_data.at[index, 'b'] = 1 + gamma*(1/propensity[int(row['St'])][int(row['Xt'])] - 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Et</th>\n",
       "      <th>Mt</th>\n",
       "      <th>St</th>\n",
       "      <th>Xt</th>\n",
       "      <th>Yt</th>\n",
       "      <th>pt_id</th>\n",
       "      <th>t</th>\n",
       "      <th>r</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.551680</td>\n",
       "      <td>1.794420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.551679</td>\n",
       "      <td>2.258781</td>\n",
       "      <td>2.812644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>2.258781</td>\n",
       "      <td>2.812644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>2.258781</td>\n",
       "      <td>2.812644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.551679</td>\n",
       "      <td>1.551680</td>\n",
       "      <td>1.794420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   Et   Mt   St   Xt   Yt  pt_id    t         r         a         b\n",
       "0      0  0.0  1.0  0.0  1.0  0.0    0.0  0.0  0.000000  1.551680  1.794420\n",
       "1      1  0.0  0.0  0.0  0.0  1.0    0.0  1.0 -0.551679  2.258781  2.812644\n",
       "2      2  0.0  0.0  0.0  0.0  0.0    0.0  2.0 -0.000000  2.258781  2.812644\n",
       "3      3  0.0  0.0  0.0  0.0  0.0    0.0  3.0 -0.000000  2.258781  2.812644\n",
       "4      4  0.0  1.0  0.0  1.0  1.0    0.0  4.0  0.551679  1.551680  1.794420"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_data_sorted = cr_data.sort_values(by='r').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>Et</th>\n",
       "      <th>Mt</th>\n",
       "      <th>St</th>\n",
       "      <th>Xt</th>\n",
       "      <th>Yt</th>\n",
       "      <th>pt_id</th>\n",
       "      <th>t</th>\n",
       "      <th>r</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16864</td>\n",
       "      <td>21264</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>-0.551679</td>\n",
       "      <td>2.258781</td>\n",
       "      <td>2.812644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6909</td>\n",
       "      <td>9209</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.551679</td>\n",
       "      <td>2.258781</td>\n",
       "      <td>2.812644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10884</td>\n",
       "      <td>13884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>-0.551679</td>\n",
       "      <td>2.258781</td>\n",
       "      <td>2.812644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24986</td>\n",
       "      <td>31186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>-0.551679</td>\n",
       "      <td>2.258781</td>\n",
       "      <td>2.812644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13817</td>\n",
       "      <td>17217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-0.551679</td>\n",
       "      <td>2.258781</td>\n",
       "      <td>2.812644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  index   Et   Mt   St   Xt   Yt  pt_id     t         r         a  \\\n",
       "0    16864  21264  1.0  1.0  0.0  0.0  1.0  212.0  64.0 -0.551679  2.258781   \n",
       "1     6909   9209  1.0  1.0  0.0  0.0  1.0   92.0   9.0 -0.551679  2.258781   \n",
       "2    10884  13884  0.0  0.0  0.0  0.0  1.0  138.0  84.0 -0.551679  2.258781   \n",
       "3    24986  31186  0.0  0.0  0.0  0.0  1.0  311.0  86.0 -0.551679  2.258781   \n",
       "4    13817  17217  1.0  1.0  0.0  0.0  1.0  172.0  17.0 -0.551679  2.258781   \n",
       "\n",
       "          b  \n",
       "0  2.812644  \n",
       "1  2.812644  \n",
       "2  2.812644  \n",
       "3  2.812644  \n",
       "4  2.812644  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr_data_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lambda(k, data_sorted):\n",
    "    num = ((data_sorted.index<k)*(data_sorted['a']*data_sorted['r'])).sum() +\\\n",
    "    ((data_sorted.index>=k)*(data_sorted['b']*data_sorted['r'])).sum()\n",
    "    den = ((data_sorted.index<k)*data_sorted['a']).sum() +\\\n",
    "    ((data_sorted.index>=k)*data_sorted['b']).sum()\n",
    "    return num/den    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As proved in the paper, the worst case regret estimate $\\hat{\\bar{Q}}(r;W_n^\\Gamma) = \\lambda(k^*)$  \n",
    "where $k^* = \\inf\\{k=1,\\dots,n+1:\\lambda(k)<\\lambda(k-1)\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst case regret is 0.014751351154487691\n"
     ]
    }
   ],
   "source": [
    "lbd = compute_lambda(0, cr_data_sorted)\n",
    "next_lbd = compute_lambda(1, cr_data_sorted)\n",
    "i = 2\n",
    "while i < len(cr_data_sorted) and  lbd <= next_lbd:\n",
    "    lbd = next_lbd\n",
    "    next_lbd = compute_lambda(i, cr_data_sorted)\n",
    "    i += 1\n",
    "if next_lbd < lbd:\n",
    "    print('Worst case regret is', next_lbd)\n",
    "else:\n",
    "    print('k* is infinity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bring this all together in a function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_worst_case_regret(data, pi, pi0, gamma):\n",
    "    n_states = len(pi)\n",
    "    n_actions = len(pi[0])\n",
    "    sums = compute_state_action_visits(data, n_states, n_actions)\n",
    "    physpol = (sums.T/((sums.sum(axis=1)==0) + (sums.sum(axis=1)))).T\n",
    "    propensity = physpol\n",
    "    cr_data = data.copy()\n",
    "    for index, row in cr_data.iterrows():\n",
    "        cr_data.at[index, 'r'] = (physpol[int(row['St'])][int(row['Xt'])]-pi[int(row['St'])][int(row['Xt'])])*row['Yt']\n",
    "        cr_data.at[index, 'a'] = 1 + 1/gamma*(1/propensity[int(row['St'])][int(row['Xt'])] - 1)\n",
    "        cr_data.at[index, 'b'] = 1 + gamma*(1/propensity[int(row['St'])][int(row['Xt'])] - 1)\n",
    "    cr_data_sorted = cr_data.sort_values(by='r').reset_index()\n",
    "    lbd = compute_lambda(0, cr_data_sorted)\n",
    "    next_lbd = compute_lambda(1, cr_data_sorted)\n",
    "    i = 2\n",
    "    while i < len(cr_data_sorted) and  lbd <= next_lbd:\n",
    "        lbd = next_lbd\n",
    "        next_lbd = compute_lambda(i, cr_data_sorted)\n",
    "        i += 1\n",
    "    if next_lbd < lbd:\n",
    "        print('Worst case regret is', next_lbd)\n",
    "        return next_lbd\n",
    "    else:\n",
    "        print('k* is infinity')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the same with policy $\\pi$ obtained by 'softening' the deterministic policy  \n",
    "$\\pi(X_t = 1 | S_t = 0) = 1$  \n",
    "$\\pi(X_t = 0 | S_t = 1) = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05, 0.95],\n",
       "       [0.95, 0.05]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi = np.zeros((2,2))\n",
    "pi[0][0] = 0.05\n",
    "pi[0][1] = 0.95\n",
    "pi[1][0] = 0.95\n",
    "pi[1][1] = 0.05\n",
    "pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst case regret is 0.005962859346932289\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.005962859346932289"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_worst_case_regret(train_data, pi, physpol, gamma=1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the degree of unmeasured confounding\n",
    "Now let's assume that we only have access to $S_t$ and $E_t$. $M_t$ is an unobserved confounder. In this case, the state space has 4 states. The action space remains unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Et</th>\n",
       "      <th>Mt</th>\n",
       "      <th>St</th>\n",
       "      <th>Xt</th>\n",
       "      <th>Yt</th>\n",
       "      <th>pt_id</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   Et   Mt   St   Xt   Yt  pt_id    t\n",
       "0      0  0.0  1.0  0.0  1.0  0.0    0.0  0.0\n",
       "1      1  0.0  0.0  0.0  0.0  1.0    0.0  1.0\n",
       "2      2  0.0  0.0  0.0  0.0  0.0    0.0  2.0\n",
       "3      3  0.0  0.0  0.0  0.0  0.0    0.0  3.0\n",
       "4      4  0.0  1.0  0.0  1.0  1.0    0.0  4.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_model2 = train_data.copy()\n",
    "train_data_model2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>St</th>\n",
       "      <th>Xt</th>\n",
       "      <th>Yt</th>\n",
       "      <th>pt_id</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   St   Xt   Yt  pt_id    t\n",
       "0      0  0.0  1.0  0.0    0.0  0.0\n",
       "1      1  0.0  0.0  1.0    0.0  1.0\n",
       "2      2  0.0  0.0  0.0    0.0  2.0\n",
       "3      3  0.0  0.0  0.0    0.0  3.0\n",
       "4      4  0.0  1.0  1.0    0.0  4.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_model2['St'] = train_data_model2['St'] + 2*train_data_model2['Et']\n",
    "train_data_model2.drop(columns = ['Et', 'Mt'], inplace=True)\n",
    "train_data_model2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal policy $\\pi^*$\n",
    "We know from the complete model dynamics that the optimal policy $\\pi^*$ in this case is:  \n",
    "$(S_t, E_t)$ -> Optimal Action  \n",
    "(0,0) -> 1  \n",
    "(0,1) -> 0  \n",
    "(1,0) -> 1  \n",
    "(1,1) -> 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soften_deterministic_policy(policy):\n",
    "    p = 0.05\n",
    "    n_states = len(policy)\n",
    "    n_actions = len(policy[0])\n",
    "    for i in range(len(policy)):\n",
    "        for j in range(len(policy[i])):\n",
    "            if policy[i][j] == 0:\n",
    "                policy[i][j] = p/(n_actions-1)\n",
    "            elif policy[i][j] == 1:\n",
    "                policy[i][j] = 1-p\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A policy which always picks action 0 must have higher regret than the optimal policy $\\pi^*$ relative to the physician's policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95, 0.05],\n",
       "       [0.95, 0.05],\n",
       "       [0.95, 0.05],\n",
       "       [0.95, 0.05]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi = np.zeros((4,2))\n",
    "pi[0][0] = 1\n",
    "pi[1][0] = 1\n",
    "pi[2][0] = 1\n",
    "pi[3][0] = 1\n",
    "soften_deterministic_policy(pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2468884 , 0.7531116 ],\n",
       "       [0.75356619, 0.24643381],\n",
       "       [0.74812757, 0.25187243],\n",
       "       [0.25157401, 0.74842599]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sums = compute_state_action_visits(train_data_model2, n_states=4, n_actions=2)\n",
    "physpol = (sums.T/((sums.sum(axis=1)==0) + (sums.sum(axis=1)))).T\n",
    "physpol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst case regret is 0.025080322071306414\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.025080322071306414"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_worst_case_regret(train_data_model2, soften_deterministic_policy(pi), physpol, gamma=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_star = np.zeros((4,2))\n",
    "pi_star[0][1] = 1\n",
    "pi_star[1][1] = 1\n",
    "pi_star[2][0] = 1\n",
    "pi_star[3][0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst case regret is -0.011051029909470916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.011051029909470916"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_worst_case_regret(train_data_model2, soften_deterministic_policy(pi_star), physpol, gamma=1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat this with policy $\\pi$ which is complement to the optimal policy $\\pi^*$.  \n",
    "This is, of course, the worst policy in terms of value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = np.zeros((4,2))\n",
    "pi[0][0] = 1\n",
    "pi[1][0] = 1\n",
    "pi[2][1] = 1\n",
    "pi[3][1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst case regret is 0.04131427647793238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.04131427647793238"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_worst_case_regret(train_data_model2, soften_deterministic_policy(pi), physpol, gamma=1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute worst case regret for a uniform policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5, 0.5],\n",
       "       [0.5, 0.5],\n",
       "       [0.5, 0.5],\n",
       "       [0.5, 0.5]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi = np.ones((4,2))*0.5\n",
    "pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst case regret is 0.01033874507388746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.01033874507388746"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_worst_case_regret(train_data_model2, pi, physpol, gamma=1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy evaluations and worst case regret under unobserved confounding\n",
    "We do a systematic analysis of all deterministic policies, comparing their value (using Weighted Importance Sampling, assuming no unobserved confounding) to their worst case regret, relative to the physician's policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_deterministic_policies(n_states, n_actions):\n",
    "    result = []\n",
    "    for i in range(n_actions**n_states):\n",
    "        policy = np.zeros(n_states)\n",
    "        policy[0] = i%2 \n",
    "        policy[1] = ((i-policy[0])/2) % 2 \n",
    "        policy[2] = ((i-policy[0]-2*policy[1])/4) % 2\n",
    "        policy[3] = ((i-policy[0]-2*policy[1] - 4*policy[2])/8) % 2\n",
    "        result.append(policy)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_policy_into_softened_matrix(policy, n_actions):\n",
    "    pi = np.zeros((len(policy), n_actions))\n",
    "    for s in range(len(policy)):\n",
    "        pi[s][int(policy[s])] = 1\n",
    "    return soften_deterministic_policy(pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bootwis_estimator</th>\n",
       "      <th>policy</th>\n",
       "      <th>worst_case_regret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.849613</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0.025080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.611379</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>-0.003182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.553125</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>0.016080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.983051</td>\n",
       "      <td>[1.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>-0.011051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.102709</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>0.037798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16.761323</td>\n",
       "      <td>[1.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>0.008874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11.933816</td>\n",
       "      <td>[0.0, 1.0, 1.0, 0.0]</td>\n",
       "      <td>0.028842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.614686</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.0]</td>\n",
       "      <td>-0.000154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.101396</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>0.028615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12.649414</td>\n",
       "      <td>[1.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>-0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12.378043</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0]</td>\n",
       "      <td>0.019654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15.398756</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0]</td>\n",
       "      <td>-0.007925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14.984175</td>\n",
       "      <td>[0.0, 0.0, 1.0, 1.0]</td>\n",
       "      <td>0.041314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16.136879</td>\n",
       "      <td>[1.0, 0.0, 1.0, 1.0]</td>\n",
       "      <td>0.012431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12.025527</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>0.032397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12.659561</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>0.003417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bootwis_estimator                policy  worst_case_regret\n",
       "0           16.849613  [0.0, 0.0, 0.0, 0.0]           0.025080\n",
       "1           14.611379  [1.0, 0.0, 0.0, 0.0]          -0.003182\n",
       "2           12.553125  [0.0, 1.0, 0.0, 0.0]           0.016080\n",
       "3           15.983051  [1.0, 1.0, 0.0, 0.0]          -0.011051\n",
       "4           16.102709  [0.0, 0.0, 1.0, 0.0]           0.037798\n",
       "5           16.761323  [1.0, 0.0, 1.0, 0.0]           0.008874\n",
       "6           11.933816  [0.0, 1.0, 1.0, 0.0]           0.028842\n",
       "7           12.614686  [1.0, 1.0, 1.0, 0.0]          -0.000154\n",
       "8           14.101396  [0.0, 0.0, 0.0, 1.0]           0.028615\n",
       "9           12.649414  [1.0, 0.0, 0.0, 1.0]          -0.000086\n",
       "10          12.378043  [0.0, 1.0, 0.0, 1.0]           0.019654\n",
       "11          15.398756  [1.0, 1.0, 0.0, 1.0]          -0.007925\n",
       "12          14.984175  [0.0, 0.0, 1.0, 1.0]           0.041314\n",
       "13          16.136879  [1.0, 0.0, 1.0, 1.0]           0.012431\n",
       "14          12.025527  [0.0, 1.0, 1.0, 1.0]           0.032397\n",
       "15          12.659561  [1.0, 1.0, 1.0, 1.0]           0.003417"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from offpolicy_eval import *\n",
    "\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "n_states = 4\n",
    "n_actions = 2\n",
    "\n",
    "policies = get_all_deterministic_policies(n_states, n_actions)\n",
    "\n",
    "for pi in policies:\n",
    "    _, bootwis_estimator = evaluate_policy(train_data_model2, pi, n_states, n_actions, 0.99, n_iters=50)\n",
    "    pi_mat = turn_policy_into_softened_matrix(pi, n_actions)\n",
    "    regret = compute_worst_case_regret(train_data_model2, pi_mat, physpol, gamma=1.2)\n",
    "    results_df = results_df.append({'policy': pi, 'bootwis_estimator': bootwis_estimator.mean(), 'worst_case_regret': regret}, ignore_index=True)\n",
    "    \n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fc5e92dc5e0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = results_df['bootwis_estimator']\n",
    "y = results_df['worst_case_regret']\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above shows that worst case regret is a better proxy for policy value than WIS estimator. For instance,  \n",
    "The optimal policy $\\pi^*$ has lowest regret, but not the highest WIS estimator value.  \n",
    "Similarly the worst policy $\\pi$, which acts suboptimally at each decision, has the highest regret, whereas it's WIS estimator value is still quite high."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
